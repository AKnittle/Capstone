---
title: "Capstone: Neural Network"
author: "Andrew Knittle"
date: "`r paste('Generated on', Sys.Date())`" 
output: 
  html_document: 
    # try readable or cosmo
    # default (default), try kable, tibble, or paged as an option
    # Options are none (default), show, and hide
    # default is null, try my_style_file.css
    toc: TRUE
    toc_depth: 3
    toc_float: FALSE
    highlight: haddock
    theme: flatly
    df_print: paged
    code_folding: none
    self_contained: TRUE
---

```{r setup, include=FALSE}
# --------------------------------------
# Clean and Prep Environment
rm(list=ls())
set.seed(123)

# --------------------------------------
# Load Libraries
library(pacman)
p_load(ggplot2)
p_load(dplyr)
p_load(psych)
p_load(ggpubr)
p_load(kableExtra)
p_load(corrplot)
p_load(tidyverse)
p_load(caret)
p_load(MASS)
p_load(ISLR)
p_load(glm.predict)
p_load(glmnet)
p_load(modelr)
p_load(boot)
p_load(pROC)

p_load(neuralnet)
p_load(deepnet)
p_load(mlbench)
p_load(h2o)
# Formatting----------------------------
p_load(kable)
p_load(kableExtra)

# --------------------------------------
# Read Data
setwd(dirname(rstudioapi::getSourceEditorContext()$path))


logDustData = as.data.frame(read.csv('Data/logDustData_Reduced.csv',header=T,sep=','))
logDustData <- logDustData[-1]
logDustData <- logDustData[-1]
logDustData$CASESTAT <- as.factor(logDustData$CASESTAT)
logDustData <- na.omit(logDustData[,c(1:27, 30)])


# --------------------------------------
# Read helper script
source("Exploratory_Support_Scripts.R")
source("CrossValidation_Library.R")
source("Model_Building_Library.R")
source("Script_Library.R")


```

# Methods

Neural Networks are designed to mimic to structure of the human brain in terms of individual neurons. Neural Networks can be very powerful at prediction, but this comes at the cost of being almost impossible to interpret and at times incredibly resource intensive. This section will do the best it can at describing how they work at a high level.

## Structure

[In the most basic understanding of a Neural Network](https://youtu.be/CqOfi41LfDw?t=228) it is a collection of nodes and connections between those nodes that form a graph. Each of these connections have weights assigned to them via a technique called **Backpropagation** (this will be explained later in this section). Each node then adds pieces of an output together to form a final output, think of each node adding a puzzle piece together to form the whole picture. These "puzzle pieces" in each  node are technically called an ["Activation Function"](https://www.youtube.com/watch?v=CqOfi41LfDw&ab_channel=StatQuestwithJoshStarmer); these are typically Sigmoid or ReLU Functions, but other functions can be considered based on the preference of the one building the network. 
Neural Networks can have several input or output nodes, and several layers of internal nodes called *hidden nodes*.

## Traversal of the Network

For sake of being explainable we will assume that the Neural Network for this section has 1 Input Node, 1 Hidden Layer of 2 Nodes, and 1 Output Node. Also the functions for each of the connections will already be made through Backpropagation; we're traversing not building. 

We start by plugging in a value $n_0$ into the the Input Node "Alpha". From Alpha we have two connections, each to a separate hidden node, H1 and H2 respectively. The connection from Alpha to H1 is processed through a function, say $n*0.5 + 1$; the multiplier is a ["weight" and the additive value is called a "bias"](https://www.youtube.com/watch?v=CqOfi41LfDw&ab_channel=StatQuestwithJoshStarmer). The value from this "connection function" is then used to **find the x-coordinate of H1's Activation Function**. Plugging in that $x$ value into the Activation Function gives us a new value, $n_1$.

From the node H1 we traverse, with our new value $n_1$, to the output node "Omega". On that connection we apply another connection function let's say $n_1*(-0.25)$ to give us $n_{1f}$.

However, before we reach Omega we need to do the same process as before but to H2. The connection function from Alpha to H2 will be $n*0.25 -1$, this value is plugged into H2's activation function and this gives us $n_2$. Since both connections have different values the [*range of the activation functions of H1 and H2 will be different.*](https://www.youtube.com/watch?v=CqOfi41LfDw&ab_channel=StatQuestwithJoshStarmer)

We do the same procedure as before from H1 to Omega but this time from H2 to Omega. We'll have the connection function be $n_2*.75$ to give us $n_{2f}$.

However before we plug $n_{1f}$ and $n_{2f}$ we need to sum them together as $n_{sum}$ and finally we apply one more connection function $n_{sum} + 2$ to give us $n_{final}$. $n_{final}$ is the final output, from Omega, for the value of $n$. Thus we have completed our traversal of the network.

## Backpropagation

Before we talk about Backpropagation we need to discuss some foundational topics, the *Chain Rule* and *Gradient Descent*. Both subsections are a very brief overview of how each work.

### Chain Rule

In short [The Chain Rule](https://www.youtube.com/watch?v=wl1myxrtQHQ&ab_channel=StatQuestwithJoshStarmer) is like a transitive property of derivatives. 

A very simple example is:
$$
\text{Given the functions: }
\\
y=2x \text{ -> } \frac{dy}{dx}=2
\\
w=5y \text{ -> } \frac{dw}{dy}=5
\\
\text{We can use the chain rule to get: }
\\
\frac{dw}{dy}*\frac{dy}{dx} \text{ -> } \frac{dw}{dx}=10 \text{ -> } w=10x 
$$
This simple example can scale out to more complex algorithms. Having a unit, in this case $y$, connecting between two other units. This is a much simpler approach than directly plugging in functions directly into other functions that are wrapped around them and taking that larger function's derivative. If you've taken Calculus course before then this was likely review. 

The Chain Rule applies in machine learning, and thus Neural Networks, when we want to [reduce the Residual Sum of Squares](https://youtu.be/wl1myxrtQHQ?t=707). Essentially we want to find what we can get minimum Residual Sum of Squares (slope of 0), and different parts of the regression can be solved for by using the Chain Rule to solve for it.

### Gradient Descent

Gradient Descent attempts to find the [minimum Residual Sum of Squares to build out a statistical model by taking steps to zone in on the ideal value by taking steps that start large and get smaller as you get closer to the minimum.](https://www.youtube.com/watch?v=sDv4f4s2SB8&ab_channel=StatQuestwithJoshStarmer). Basically Gradient Descent utilizes the Chain Rule to build out the terms for the model, but instead of solving for the slope being 0 steps are (starting at random place) and then trying. Take a step, see what the slope is and take step depending on what the slope is; closer to 0 you take smaller steps. The changes in Step Sizes is called the "Learning Rate", $\text{Step Size}=\text{Model Term}*\text{Learning Rate}$. Most of the time a limit amount of steps are set in place because at some point it can be impractical.

[In summary:](https://youtu.be/sDv4f4s2SB8?t=1333)

* 1. We use the Loss Function to evaluate how well the line fits the data (Sum of Squared Residuals)

* 2. We take the derivative of the Loss Function or the derivative of the Sum of Squares Residuals. 

* 3. Then we take a random value of the term of the model and calculate the derivative when it's at said random variable.

* 4. Get the Step Size, using the current slope multiplied by the Learning Rate

* 5. Get the new term value by taking the old term value from Step 3 and subtracting that by the step size.

* 6. Get the derivative of new term from Step 5 and repeat until converging at slope is 0 or meeting the maximum number of steps.

[This can be done at once for a number of different terms.](https://youtu.be/sDv4f4s2SB8?t=950)

### How Backpropagation Works

[Backpropagation](https://youtu.be/IN2XmBhILt4?t=92) is what sets the weights (the multiplier) and biases (the additive) for connections between nodes. Backpropagation uses the Chain Rule to calculate derivatives and plugging the derivatives into Gradient Descent to optimize the parameters (weights and biases).

Backpropagation normally starts on the last parameter in the network and then works backwards from there to fill in the previous parameters. So parameters are propagated backwards through the network, hence the name. However, we can start with having all the other parameters filled in but the last one, the final bias. We then calculate SSR on a range of values to find the what bias gives us the lowest SSR, but to save time we use Gradient Descent rather go through a massive range of values. 

[To find the optimal bias we want to use Gradient Descent](https://youtu.be/IN2XmBhILt4?t=515), and that means we need to take the derivative of the SSR with respect to bias. Because the SSR are linked to bias by the predicted values the Chain Rule can be applied to solve for the derivative of the SSR with respect to bias. The Chain Rule says that the derivative of the SSR with respect to bias is the derivative of the SSR with respect to the Predicted values times the derivative of the Predicted values with respect to bias.

<To be continued...>


# Model Building & Performance

```{r Model Building wtih deepnet, echo=FALSE, fig.cap= "Model Building with deepnet", out.height="100%", out.width="100%", warning=FALSE, comment=FALSE, warning=FALSE}

# Prep the data to work with the "deepnet" package
# https://srdas.github.io/DLBook/DeepLearningWithR.html

cancerVal = as.numeric(as.matrix(logDustData$CASESTAT)) # Cast the dependent variable as a matrix
predictMatrix = as.matrix(logDustData[,1:27], ncol=27) # Build Matrix of predictors

# Begin the training
# hidden is the number of nodes in the first layer is x
# nn <- nn.train(predictMatrix, cancerVal, hidden = c(5))
network <- buildNetwork.deepnet(cancerVal, predictMatrix, c(5))

```


```{r Model Building wtih neuralnet, echo=FALSE, fig.cap= "Model Building with neuralnet", out.height="100%", out.width="100%", warning=FALSE, comment=FALSE, warning=FALSE}


# model.Nnet <- buildNetwork.neuralnet(logDustData, "CASESTAT", c(5))
# model.Nnet[[2]]
# plot(model.Nnet[[1]])
```

# Conclusion

At the end of the day this was an impractical method to use with resources I had on hand. Also to be able to explain how the model worked would be really hard to explain. For this reason trying to use Neural Networks did not precede further then some exploratory test runs.


