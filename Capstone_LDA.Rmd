---
title: "Capstone: LDA"
author: "Andrew Knittle"
date: "`r paste('Generated on', Sys.Date())`" 
output: 
  html_document: 
    # try readable or cosmo
    # default (default), try kable, tibble, or paged as an option
    # Options are none (default), show, and hide
    # default is null, try my_style_file.css
    toc: TRUE
    toc_depth: 3
    toc_float: FALSE
    highlight: haddock
    theme: flatly
    df_print: paged
    code_folding: none
    self_contained: TRUE
---

```{r setup, include=FALSE}
# --------------------------------------
# Clean and Prep Environment
rm(list=ls())
set.seed(123)

# --------------------------------------
# Load Libraries
library(pacman)
p_load(ggplot2)
p_load(ISLR)
p_load(dplyr)
p_load(psych)
p_load(ggpubr)
p_load(kableExtra)
p_load(corrplot)
p_load(tidyverse)
p_load(caret)
p_load(MASS)
p_load(glm.predict)
p_load(glmnet)
p_load(boot)
# Formatting----------------------------
p_load(kable)
p_load(kableExtra)

# --------------------------------------
# Read Data
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
logDustData = as.data.frame(read.csv('Data/logDustData_Reduced.csv',header=T,sep=','))
logDustData <- logDustData[-1]
logDustData <- logDustData[-1]
logDustData$CASESTAT <- as.factor(logDustData$CASESTAT)
logDustData <- na.omit(logDustData[,c(1:27, 30)])

# train_DustData <- as.data.frame(read.csv('Data/Training Set_0.9_May 25 2021.csv',header=T,sep=','))[-1]
# train_DustData$CASESTAT <- as.numeric(train_DustData$CASESTAT)
# train_DustData <- na.omit(train_DustData[,c(1:27, 30)])

# --------------------------------------
# Read helper script
source("Exploratory_Support_Scripts.R")
source("Script_Library.R")
source("CrossValidation_Library.R")
source("Model_Building_Library.R")



```

# Method

[Linear Discriminatory Analysis (LDA) focuses on maximizing the separability among known categories,](https://www.youtube.com/watch?v=azXCzI57Yfc&t=641s&ab_channel=StatQuestwithJoshStarmer) in this case it's positive and negative cancer results. This is done via a "cut", or plain, to create the separation. [LDA starts by creating a new axis that satisfies two criteria](https://youtu.be/azXCzI57Yfc?t=447):

 * 1. Maximize the distance between means of each category.
 
 * 2. Minimize the variation, or "scatter" $s^2$, within each category.
 
This can be represented as $\frac{(\mu_1-\mu_2)^2}{s_1^2 + s_2^2}$. A large numerator and a small denominator is ideal. Once this new axis is created points are then projected onto it. This is done on each feature, where ["the linear combination of predictor variables that are used to form the LDA decision rule."](http://www.sthda.com/english/articles/36-classification-methods-essentials/146-discriminant-analysis-essentials-in-r/) In other words these variables are used to find the best linear combination of them to help best distinguish data across the two groups. [For each individual LDA finds the probability of belonging to the different groups, and whichever probability is the highest per group that individual is assigned to said group.](http://www.sthda.com/english/articles/36-classification-methods-essentials/146-discriminant-analysis-essentials-in-r/)

An important quirk about LDA is that it only works on continuous independent variables because a categorical variable has no mean or variation, it's either one thing or another. This is perfect for the amount of chemicals detected as they are all continuous features. 

It functions similarly to Principle Component Analysis (PCA) by creating new axes and reducing dimensions. PCA does this by looking at the variation of features while LDA looks at variation between categories and maximize their separation.

# Performance

```{r Model Building, echo=FALSE, fig.cap= "Model Building", out.height="100%", out.width="100%", warning=FALSE, comment=FALSE, warning=FALSE}


# Reattempting with my swiss army cross validator and with the full log data set
lda.formula <- formula(CASESTAT ~ .)
lda.fit <- lda(lda.formula, data = logDustData)
ldaCross <- crossValidator.byKPercent(df = logDustData, response = "CASESTAT", formula = lda.formula, family="lda")

# Plot LDA

lda.data <- cbind(logDustData, predict(lda.fit)$x)
ggplot(lda.data) +
  aes(x = LD1, fill = CASESTAT) +
  geom_histogram(bins = 30L) +
  scale_fill_hue(direction = -1) +
  theme_bw() +
  facet_grid(rows = vars(CASESTAT))

# Print results of LDA
errorsDF <- ldaCross[[1]]
errorSummary <- crossError(errorsDF)
quickDFPrint(errorSummary[[1]])
errorSummary[[2]]

validCross <- ldaCross[[4]]
confuseDF <- rawConfusionBuilder(validCross$Response, validCross$holdout.rawPredict)
quickDFPrint(confuseDF[[1]])
quickDFPrint(confuseDF[[2]])


```


# Conclusion

We can see from the LDA histogram plot that there is a lot of cross over which is the opposite of what we should be seeing if this is model was good at discriminating between groups.





